{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Privacy Meter Demo"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook is an interactive demonstration of running Privacy Meter to audit privacy defined by **MIA**, which is the default auditing methodology. For a detailed explanation on MIA and how to run from bash instead, please refer to the [documentation](../documentation/mia.md)\n",
   "id": "cc42450cd38a3551"
  },
  {
   "cell_type": "markdown",
   "id": "83217c64",
   "metadata": {},
   "source": [
    "## Setting up the Colab environment\n",
    "\n",
    "If you are running it offline, you can skip to \"Importing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1759435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the github repo\n",
    "!git clone https://github.com/privacytrustlab/ml_privacy_meter.git\n",
    "\n",
    "# Update the Colab environment\n",
    "!pip install datasets==2.21.0 transformers==4.44.2 torch==2.4.1 torchvision==0.19.1 torchaudio"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Change the directory to the cloned repo\n",
    "import sys\n",
    "sys.path.append('/content/ml_privacy_meter/')\n",
    "\n",
    "%cd ml_privacy_meter"
   ],
   "id": "4a7c1b96126edf59"
  },
  {
   "cell_type": "markdown",
   "id": "b243137d",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70647b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiashu/miniconda/envs/privacy_meter/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from privacy_meter.audit import get_average_audit_results, audit_models, sample_auditing_dataset\n",
    "from privacy_meter.get_signals import get_model_signals\n",
    "from privacy_meter.models.utils import load_models, train_models, split_dataset_for_training\n",
    "from privacy_meter.util import (\n",
    "    check_configs,\n",
    "    setup_log,\n",
    "    initialize_seeds,\n",
    "    create_directories,\n",
    "    load_dataset,\n",
    ")\n",
    "\n",
    "# Enable benchmark mode in cudnn to improve performance when input sizes are consistent\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c129ff11",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9703b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = \"configs/config.yaml\"\n",
    "with open(configs, \"rb\") as f:\n",
    "        configs = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# Validate configurations\n",
    "check_configs(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f957267",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70856708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate configurations\n",
    "check_configs(configs)\n",
    "\n",
    "# Initialize seeds for reproducibility\n",
    "initialize_seeds(configs[\"run\"][\"random_seed\"])\n",
    "\n",
    "# Create necessary directories\n",
    "log_dir = configs[\"run\"][\"log_dir\"]\n",
    "directories = {\n",
    "    \"log_dir\": log_dir,\n",
    "    \"report_dir\": f\"{log_dir}/report\",\n",
    "    \"signal_dir\": f\"{log_dir}/signals\",\n",
    "    \"data_dir\": configs[\"data\"][\"data_dir\"],\n",
    "}\n",
    "create_directories(directories)\n",
    "\n",
    "# Set up logger\n",
    "logger = setup_log(\n",
    "    directories[\"report_dir\"], \"time_analysis\", configs[\"run\"][\"time_log\"]\n",
    ")\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1e51a",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea18682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 22:24:56,396 INFO     Load data from data/cifar10.pkl\n",
      "2024-10-25 22:24:56,397 INFO     The whole dataset size: 60000\n",
      "2024-10-25 22:24:56,398 INFO     Loading dataset took 0.09912 seconds\n"
     ]
    }
   ],
   "source": [
    "baseline_time = time.time()\n",
    "dataset, population = load_dataset(configs, directories[\"data_dir\"], logger)\n",
    "logger.info(\"Loading dataset took %0.5f seconds\", time.time() - baseline_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79b730",
   "metadata": {},
   "source": [
    "## Load or train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410036b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 22:26:25,183 INFO     Loading model 0\n",
      "2024-10-25 22:26:25,202 INFO     Loading model 1\n",
      "2024-10-25 22:26:25,217 INFO     Loading model 2\n",
      "2024-10-25 22:26:25,230 INFO     Loading model 3\n",
      "2024-10-25 22:26:25,243 INFO     Model loading/training took 0.1 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define experiment parameters\n",
    "num_experiments = configs[\"run\"][\"num_experiments\"]\n",
    "num_reference_models = configs[\"audit\"][\"num_ref_models\"]\n",
    "num_model_pairs = max(math.ceil(num_experiments / 2.0), num_reference_models + 1)\n",
    "\n",
    "# Load or train models\n",
    "baseline_time = time.time()\n",
    "models_list, memberships = load_models(\n",
    "    log_dir, dataset, num_model_pairs * 2, configs, logger\n",
    ")\n",
    "if models_list is None:\n",
    "    # Split dataset for training two models per pair\n",
    "    data_splits, memberships = split_dataset_for_training(\n",
    "        len(dataset), num_model_pairs\n",
    "    )\n",
    "    models_list = train_models(\n",
    "        log_dir, dataset, data_splits, memberships, configs, logger\n",
    "    )\n",
    "logger.info(\n",
    "    \"Model loading/training took %0.1f seconds\", time.time() - baseline_time\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563455e3",
   "metadata": {},
   "source": [
    "## Prepare auditing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f92be589",
   "metadata": {},
   "outputs": [],
   "source": [
    "auditing_dataset, auditing_membership = sample_auditing_dataset(\n",
    "        configs, dataset, logger, memberships\n",
    "    )\n",
    "\n",
    "# Also downsample the population set size if specified in the config\n",
    "population = Subset(\n",
    "    population,\n",
    "    np.random.choice(\n",
    "        len(population),\n",
    "        configs[\"audit\"].get(\"population_size\", len(population)),\n",
    "        replace=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136fb3f",
   "metadata": {},
   "source": [
    "## Compute signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d65983a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 22:27:11,146 INFO     Signals loaded from disk.\n",
      "2024-10-25 22:27:11,147 INFO     Preparing signals took 0.00190 seconds\n"
     ]
    }
   ],
   "source": [
    "baseline_time = time.time()\n",
    "signals = get_model_signals(models_list, auditing_dataset, configs, logger)\n",
    "population_signals = get_model_signals(\n",
    "        models_list, population, configs, logger, is_population=True\n",
    "    )\n",
    "logger.info(\"Preparing signals took %0.5f seconds\", time.time() - baseline_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268e54a",
   "metadata": {},
   "source": [
    "## Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6fcf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 22:27:45,346 INFO     Fine-tuning offline_a using paired model 1\n",
      "2024-10-25 22:27:45,361 INFO     offline_a=0.00: AUC 0.7935\n",
      "2024-10-25 22:27:45,373 INFO     offline_a=0.10: AUC 0.7893\n",
      "2024-10-25 22:27:45,385 INFO     offline_a=0.20: AUC 0.7851\n",
      "2024-10-25 22:27:45,398 INFO     offline_a=0.30: AUC 0.7803\n",
      "2024-10-25 22:27:45,410 INFO     offline_a=0.40: AUC 0.7755\n",
      "2024-10-25 22:27:45,422 INFO     offline_a=0.50: AUC 0.7702\n",
      "2024-10-25 22:27:45,433 INFO     offline_a=0.60: AUC 0.7643\n",
      "2024-10-25 22:27:45,445 INFO     offline_a=0.70: AUC 0.7576\n",
      "2024-10-25 22:27:45,467 INFO     offline_a=0.80: AUC 0.7483\n",
      "2024-10-25 22:27:45,479 INFO     offline_a=0.90: AUC 0.7352\n",
      "2024-10-25 22:27:45,491 INFO     offline_a=1.00: AUC 0.6820\n",
      "2024-10-25 22:27:45,492 INFO     The best offline_a is 0.0\n",
      "2024-10-25 22:27:45,505 INFO     Target Model 0: AUC 0.7889, TPR@0.1%FPR of 0.0104, TPR@0.0%FPR of 0.0003\n",
      "2024-10-25 22:27:49,066 INFO     Auditing the privacy risks of target model 0 costs 3.7 seconds\n",
      "2024-10-25 22:27:49,067 INFO     Total runtime: 188.71941 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform the privacy audit\n",
    "baseline_time = time.time()\n",
    "target_model_indices = list(range(num_experiments))\n",
    "mia_score_list, membership_list = audit_models(\n",
    "        f\"{directories['report_dir']}/exp\",\n",
    "        target_model_indices,\n",
    "        signals,\n",
    "        population_signals,\n",
    "        auditing_membership,\n",
    "        num_reference_models,\n",
    "        logger,\n",
    "        configs,\n",
    "    )\n",
    "\n",
    "if len(target_model_indices) > 1:\n",
    "    logger.info(\n",
    "        \"Auditing privacy risk took %0.1f seconds\", time.time() - baseline_time\n",
    "    )\n",
    "\n",
    "# Get average audit results across all experiments\n",
    "if len(target_model_indices) > 1:\n",
    "    get_average_audit_results(\n",
    "        directories[\"report_dir\"], mia_score_list, membership_list, logger\n",
    "    )\n",
    "\n",
    "logger.info(\"Total runtime: %0.5f seconds\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da806a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_meter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
